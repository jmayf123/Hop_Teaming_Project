{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from tqdm.notebook import tqdm\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prefilter out all npidata csv columns that we dont need, created a new csv with the column names to keep\n",
    "save_cols = pd.read_csv('./NPPES_Data_Dissemination_February_2023/new_columns.csv', header=None)\n",
    "save_cols_list = save_cols.iloc[0,:].tolist()\n",
    "\n",
    "drop_cols = pd.read_csv('./NPPES_Data_Dissemination_February_2023/drop_cols.csv', header=None)\n",
    "drop_cols_list = drop_cols.iloc[0,:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to deal with the leading zeroes that are missing from zip codes\n",
    "\n",
    "def zip_zeroes(x):\n",
    "    if len(x) > 5:\n",
    "        return x.zfill(9)[:5]\n",
    "    elif len(x) > 0:\n",
    "        return x.zfill(5)\n",
    "    else: return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_database(save_cols_list, drop_cols_list):\n",
    "\n",
    "    #Create the 2 tables from DocGraph and NPPES downloads, \n",
    "    # and the 2 tables from the NUCC taxonomy and Zip to CBSA info \n",
    "    # and add them to a new data base called 'hop_db.sqlite'\n",
    "    \n",
    "    db = sqlite3.connect('./data/hop_db.sqlite')\n",
    "\n",
    "    ##### Table 1\n",
    "    for chunk in tqdm(pd.read_csv('./DocGraph_Hop_Teaming_2018_Commercial/DocGraph_Hop_Teaming_2018.csv', chunksize=100000)):\n",
    "        chunk = chunk[(chunk['transaction_count'] >= 25) & (chunk['average_day_wait'] < 90)] #Prefiltering accidental referrals\n",
    "        chunk.to_sql('hop', db, if_exists = 'append', index = False) \n",
    "    \n",
    "    ##### Table 2\n",
    "    for chunk in tqdm(pd.read_csv('./NPPES_Data_Dissemination_February_2023/npidata_pfile_20050523-20230212.csv', dtype=str, chunksize=100000, usecols=save_cols_list)):\n",
    "        \n",
    "        # For providers that have indicated a primary taxonomy code, pull that code into a new column\n",
    "        chunk['taxonomy_code'] = np.nan\n",
    "        \n",
    "        for n in range(1, 16):\n",
    "            x = str(n)\n",
    "            chunk.loc[chunk[f'Healthcare Provider Primary Taxonomy Switch_{x}'] == 'Y', \n",
    "                        'taxonomy_code'] = chunk[f'Healthcare Provider Taxonomy Code_{x}']\n",
    "            \n",
    "        # For providers that do not indicate a primary taxonomy code, pull the code from the first taxonomy column\n",
    "        chunk.loc[chunk['taxonomy_code'].isna(), 'taxonomy_code'] = chunk['Healthcare Provider Taxonomy Code_1'] \n",
    "        # Drop the columns no longer needed\n",
    "        chunk = chunk.drop(columns = drop_cols_list)\n",
    "        #clean up zip code column by putting missing leading zeroes back and getting the 9-digit entries down to 5\n",
    "        chunk['Provider Business Practice Location Address Postal Code'] = chunk['Provider Business Practice Location Address Postal Code'].astype(str).apply(zip_zeroes)\n",
    "        # Clean up the column names\n",
    "        chunk.columns = [x.lower()\n",
    "                 .replace('provider ', '')\n",
    "                 .replace('business ', '')\n",
    "                 .replace('practice ', '')\n",
    "                 .replace(' text', '')\n",
    "                 .replace(' (legal name)', '')\n",
    "                 .replace(' ', '_') for x in chunk.columns]  \n",
    "        \n",
    "        # append to provider table\n",
    "        chunk.to_sql('npidata', db, if_exists = 'append', index = False) \n",
    "\n",
    "    # 2 auxilary tables from other links\n",
    "    \n",
    "    ##### Table 3\n",
    "    for chunk in tqdm(pd.read_csv('./data/nucc_taxonomy_230.csv', encoding='unicode_escape', chunksize=1000)):\n",
    "        # make column names consistent with formatting of other tables\n",
    "        chunk.columns = [x.lower().replace(' ', '_') for x in chunk.columns]\n",
    "        # make the taxonomy code column name match the taxonomy code column name in the provider table\n",
    "        chunk = chunk.rename(columns = {'code' : 'taxonomy_code'})\n",
    "        chunk.to_sql('taxonomy', db, if_exists = 'append', index = False)  \n",
    "    \n",
    "    ##### Table 4\n",
    "    for chunk in tqdm(pd.read_csv('./data/ZIP_CBSA.csv', chunksize=10000)):\n",
    "        #simplify column names\n",
    "        chunk = chunk.rename(columns = {'usps_zip_pref_city' : 'city',\n",
    "                              'usps_zip_pref_state' : 'state'})\n",
    "        #get the leading zeroes back in place\n",
    "        chunk['zip'] = chunk['zip'].astype(str).str.zfill(5)\n",
    "        chunk.to_sql('zip_to_cbsa', db, if_exists = 'append', index = False)  \n",
    "\n",
    "    db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d5ec85ec5b4a84b862ae9ad35da12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d570c0756d924100b3ba1e1532002bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9afa7752184542dfbc5bc99ee057fee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9735514ba1ed4349afc37a7b329293f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "if os.path.isfile('./data/hop_db.sqlite') != True: # Make sure the data base isn't already created, this is a large DB\n",
    "    create_database(save_cols_list, drop_cols_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08210294964727e4010dccc398c44f22b92a2e77e2aceea574ad21eae77cd8e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
